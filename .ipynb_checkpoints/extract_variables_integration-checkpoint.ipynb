{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import boto3\n",
    "#import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# import spacy\n",
    "from unicodedata import normalize\n",
    "import boto3\n",
    "\n",
    "from text_detection import get_aws_analyze_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_text_to_string(df_text):\n",
    "    df_text = df_text.applymap(str)\n",
    "    string= ''\n",
    "    for i, row in df_text.iterrows():\n",
    "        line_text = ''.join(row)\n",
    "        string += line_text +'\\n'\n",
    "    return string\n",
    "\n",
    "def list_dfs_to_string(list_df_text):\n",
    "    String = ' '.join([df_text_to_string(x) for x in list_df_text])\n",
    "    return String\n",
    "\n",
    "def clean_text(s):\n",
    "    s = str(s)\n",
    "    s = re.sub(\n",
    "        r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "        normalize( \"NFD\", s), 0, re.I\n",
    "    )\n",
    "    s = normalize('NFC', s)\n",
    "    minus = s.lower()\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in minus:\n",
    "       if char not in punctuations:\n",
    "           no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def extract_dates(s):\n",
    "    try:\n",
    "        mesesDic = {\n",
    "            'enero': '01',\n",
    "            'febrero': '02',\n",
    "            'marzo': '03',\n",
    "            'abril': '04',\n",
    "            'mayo': '05',\n",
    "            'junio': '06',\n",
    "            'julio': '07',\n",
    "            'agosto': '08',\n",
    "            'septiembre': '09',\n",
    "            'octubre': '10',\n",
    "            'noviembre': '11',\n",
    "            'diciembre': '12'\n",
    "        }\n",
    "        dates = re.finditer('(?P<day>[0-9]{2}) (de) (?P<month>[a-zA-Z]+) (de|del) (?P<year>[0-9]{4})',s)\n",
    "        list_dates = []\n",
    "        for x in dates:\n",
    "            day = x.group('day')\n",
    "            month = mesesDic[x.group('month')]\n",
    "            year = x.group('year')\n",
    "            fecha = datetime.date(int(year),int(month),int(day))\n",
    "            list_dates.append(fecha)\n",
    "        list_dates.sort(reverse=True)\n",
    "        list_dates = [y.strftime('%d-%m-%Y') for y in list_dates]\n",
    "        return list_dates[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_units(s):\n",
    "    try:\n",
    "        unidades = re.finditer('((miles|millones) (de) (?P<moneda>(dolares|pesos|usd)( colombianos)?))',s,flags=2)\n",
    "        i = 0\n",
    "        for x in unidades:\n",
    "            if i ==0:\n",
    "                moneda1 = x.group()\n",
    "            moneda = x.group('moneda')\n",
    "            if moneda == 'usd':\n",
    "                return x.group()\n",
    "            if moneda == 'dolares':\n",
    "                return x.group()\n",
    "        return moneda1\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def dates_in_tables_f(list_df_tables):\n",
    "    dates_in_tables =[]\n",
    "    for df_tables in list_df_tables:\n",
    "        s = df_text_to_string(df_tables)\n",
    "        date = extract_dates(s)    \n",
    "        dates_in_tables.append(date)\n",
    "    dates_in_tables = [x for x in dates_in_tables if x]\n",
    "    dates_in_tables.sort()\n",
    "    date = dates_in_tables[-1]\n",
    "    return date\n",
    "\n",
    "def intenta_limpiar_texto(x):\n",
    "    try:\n",
    "        y=clean_text(x)\n",
    "        return y\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def loc_variable_key(list_df_tables,variable):\n",
    "    lis_dict = []\n",
    "    for hoja in range(len(list_df_tables)):\n",
    "        for col in range(list_df_tables[hoja].shape[1]):\n",
    "            for i in range(list_df_tables[hoja].shape[0]):\n",
    "                    try:\n",
    "                        s =list_df_tables[hoja].iloc[i,col]\n",
    "                        var = re.search('|'.join(v_contables_dict[variable]),s)\n",
    "                        if var:\n",
    "                            d_ubi = {s:[hoja, col, i]}\n",
    "                            lis_dict.append(d_ubi)\n",
    "                    except:\n",
    "                        pass\n",
    "    return lis_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integraci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get aws analyze document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_analyze_document' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-06549175e979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfile_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlist_df_tables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_df_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_aws_analyze_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hackbbva/G.E.T/text_detection.py\u001b[0m in \u001b[0;36mget_aws_analyze_document\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0manalyze_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maws_analyze_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manalyze_document\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mdf_tables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hackbbva/G.E.T/text_detection.py\u001b[0m in \u001b[0;36maws_analyze_document\u001b[0;34m(file_path, plot)\u001b[0m\n\u001b[1;32m    264\u001b[0m         )['Blocks']\n\u001b[1;32m    265\u001b[0m     )\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0manalyze_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_analyze_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyze_document_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0manalyze_document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_analyze_document' is not defined"
     ]
    }
   ],
   "source": [
    "bucket = 'calacaschidas'\n",
    "# bucket = 'text0detection'\n",
    "bucket_files = boto3.client('s3').list_objects(Bucket=bucket)['Contents']\n",
    "bucket_files = [x['Key'] for x in bucket_files][1:]\n",
    "\n",
    "bucket_file = 'Doc3.pdf'\n",
    "file_path = os.path.join('DownTest', bucket_file)\n",
    "if bucket_file not in os.listdir('DownTest'):\n",
    "    boto3.client('s3').download_file(\n",
    "        bucket, \n",
    "        file_path, \n",
    "        file_path\n",
    "    )\n",
    "list_df_tables, list_df_text = get_aws_analyze_document(file_path)\n",
    "\n",
    "\n",
    "'''\n",
    "# Multiple files\n",
    "bucket = 'calacaschidas'\n",
    "bucket_files = boto3.client('s3').list_objects(Bucket=bucket)['Contents']\n",
    "bucket_files = [x['Key'] for x in bucket_files][1:]\n",
    "bucket_files = ['Doc1.pdf', 'Doc2.pdf', 'Doc3.pdf']\n",
    "    \n",
    "file_tables = []\n",
    "file_text = []\n",
    "times = []\n",
    "start_time = time.time()\n",
    "for bucket_file in bucket_files:\n",
    "    begin_time = time.time()\n",
    "    print(bucket_file)\n",
    "    file_path = os.path.join('images', bucket_file)\n",
    "    if bucket_file not in os.listdir('images'):\n",
    "        boto3.client('s3').download_file(\n",
    "            bucket, \n",
    "            file_path, \n",
    "            file_path\n",
    "        )\n",
    "    df_tables, df_text = get_aws_analyze_document(file_path)\n",
    "    file_tables.append(df_tables)\n",
    "    file_text.append(df_text)\n",
    "    times.append(time.time() - begin_time)\n",
    "    print(file_path, ' - Time: ', times[-1])\n",
    "print('Total time: ', time.time() - start_time)\n",
    "print('Mean time: ', np.mean(times))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef get_first_digit_ocurrence_index(list_strings):\\n    list_indexes = list_strings.index\\n    for index, string in enumerate(list_strings):\\n        if re.search('[0-9]{1}', string) is not None:\\n            return list_indexes[index]\\n    return -1\\n\\ndef get_right_down_values(label_location):\\n    # Get right value\\n    aux = list_df_tables[label_location[0]].iloc[label_location[2]]\\n    aux = aux[label_location[1]+1:]\\n    right_index = get_first_digit_ocurrence_index(aux)\\n    right_value = ''\\n    if right_index != -1:\\n        right_value = aux[right_index]\\n    # Get down value\\n    aux = list_df_tables[0][label_location[1]][label_location[2]+1:]\\n    down_index = get_first_digit_ocurrence_index(aux)\\n    down_value = ''\\n    if down_index != -1:\\n        down_value = aux[down_index]\\n    return (right_value, down_value)\\n\\noutput_label_location = {\\n    'Total activos': [0, 2, 26]\\n}\\nfor label in output_label_location.keys():\\n    right_value, down_value = get_right_down_values(output_label_location[label])\\n    # Decisions\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_first_digit_ocurrence_index(list_strings):\n",
    "    list_indexes = list_strings.index\n",
    "    for index, string in enumerate(list_strings):\n",
    "        if re.search('[0-9]{1}', string) is not None:\n",
    "            return list_indexes[index]\n",
    "    return -1\n",
    "\n",
    "def get_right_down_values(label_location):\n",
    "    # Get right value\n",
    "    aux = list_df_tables[label_location[0]].iloc[label_location[2]]\n",
    "    aux = aux[label_location[1]+1:]\n",
    "    right_index = get_first_digit_ocurrence_index(aux)\n",
    "    right_value = ''\n",
    "    if right_index != -1:\n",
    "        right_value = aux[right_index]\n",
    "    # Get down value\n",
    "    aux = list_df_tables[0][label_location[1]][label_location[2]+1:]\n",
    "    down_index = get_first_digit_ocurrence_index(aux)\n",
    "    down_value = ''\n",
    "    if down_index != -1:\n",
    "        down_value = aux[down_index]\n",
    "    return (right_value, down_value)\n",
    "\n",
    "output_label_location = {\n",
    "    'Total activos': [0, 2, 26]\n",
    "}\n",
    "for label in output_label_location.keys():\n",
    "    right_value, down_value = get_right_down_values(output_label_location[label])\n",
    "    # Decisions\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unidades y fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = clean_text(list_dfs_to_string(list_df_text))\n",
    "Unidades = extract_units(Text)\n",
    "Fecha = extract_dates(Text)\n",
    "if not Fecha:\n",
    "    Fecha = dates_in_tables_f(list_df_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables contables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_contables_dict = {\n",
    "    'Caja y Bancos':[\n",
    "        'caja y bancos', \n",
    "        'efectivo y equivalentes en efectivo',\n",
    "        'efectivo y equivalentes de efectivo',\n",
    "    ],\n",
    "    'Total activo':[\n",
    "        'total activo',\n",
    "        'suma de los activos', \n",
    "        'activo total'\n",
    "    ],\n",
    "    'Total pasivo':[\n",
    "        'total pasivo',\n",
    "        'suma de los pasivos',\n",
    "        'pasivo total',\n",
    "        'total pasivos'\n",
    "\n",
    "    ],\n",
    "    'Total patrimonio':[\n",
    "        'total patrimonio',\n",
    "        'suma de los patrimonios',\n",
    "        'patrimonio total',\n",
    "        'patrimonio',\n",
    "        'suma del capital contable',\n",
    "        'total capital contable', \n",
    "        'total capital', \n",
    "    ],\n",
    "    'Ventas':[\n",
    "        'ventas',  \n",
    "        'ventas por operacion ordinacia',\n",
    "        'ingresos por operacion',\n",
    "        'ingresos por operacion ordinaria', \n",
    "        'ingresos operacionales', \n",
    "        'ventas brutas', \n",
    "        'ingreso por actividades ordinarias',\n",
    "        'total ingresos operacionales'\n",
    "    ],\n",
    "    'Costo de ventas':[\n",
    "        'costos de ventas', \n",
    "        'costos por ventas', \n",
    "        'costo de actividades ordinarias',\n",
    "    ],\n",
    "    'Utilidad Bruta':[\n",
    "        'utilidad bruta',\n",
    "        'perdida bruta',\n",
    "    ],\n",
    "    'utilidad operacional': [\n",
    "        'utilidad operacional', \n",
    "        'perdida operacional',\n",
    "    ],\n",
    "    'utilidad antes de impuestos': [\n",
    "        'utilidad antes de impuestos', \n",
    "        'perdida antes de impuestos',\n",
    "    ],\n",
    "    'utilidad neta': [\n",
    "        'utilidad neta', \n",
    "        'perdida neta',\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###limpieza del texto del df\n",
    "for x in range(len(list_df_tables)):\n",
    "    list_df_tables[x] = list_df_tables[x].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Caja y Bancos': [{'efectivo y equivalentes de efectivo': [0, 1, 4]}],\n",
       " 'Total activo': [{'total activos corrientes': [0, 1, 16]},\n",
       "  {'total activos no corrientes': [0, 1, 25]},\n",
       "  {'total activos': [0, 1, 26]}],\n",
       " 'Total pasivo': [{'total pasivos corrientes': [1, 1, 16]},\n",
       "  {'total pasivos no corrientes': [1, 1, 25]},\n",
       "  {'total pasivos': [1, 1, 26]},\n",
       "  {'total pasivos y patrimonio': [1, 1, 37]}],\n",
       " 'Total patrimonio': [{'pasivos y patrimonio': [1, 1, 1]},\n",
       "  {'patrimonio': [1, 1, 27]},\n",
       "  {'total de patrimonio atribuible a los propietarios de la compania': [1,\n",
       "    1,\n",
       "    34]},\n",
       "  {'total patrimonio': [1, 1, 36]},\n",
       "  {'total pasivos y patrimonio': [1, 1, 37]}],\n",
       " 'Ventas': [{'ingresos operacionales': [2, 1, 2]},\n",
       "  {'total ingresos operacionales': [2, 1, 5]},\n",
       "  {'gastos de ventas': [2, 1, 14]}],\n",
       " 'Costo de ventas': [],\n",
       " 'Utilidad Bruta': [],\n",
       " 'utilidad operacional': [],\n",
       " 'utilidad antes de impuestos': [],\n",
       " 'utilidad neta': [{'perdida utilidad neta del periodo': [2, 1, 31]}],\n",
       " 'Fecha': '31-12-2019',\n",
       " 'Unidades': 'miles de usd'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_contables = {}\n",
    "for key in v_contables_dict:\n",
    "    #print('***',key,'***')\n",
    "    variables_contables[key] = loc_variable_key(list_df_tables,key)\n",
    "    #print('\\n')\n",
    "    ##arreglar jerarquia y quedarme con uno\n",
    "\n",
    "variables = variables_contables.copy()\n",
    "variables['Fecha'] = Fecha\n",
    "variables['Unidades'] = Unidades\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('vitual_env': venv)",
   "language": "python",
   "name": "python36964bitvitualenvvenv8e357782a2eb4f0584592dc2989c5947"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
