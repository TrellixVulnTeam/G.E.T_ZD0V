{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
<<<<<<< HEAD
    "from text_detection import get_aws_analyze_document\n",
    "import os"
=======
    "import re\n",
    "\n",
    "from text_detection import get_aws_analyze_document"
>>>>>>> bfd0e2edee4bad119c75e9ec015be15e7986633e
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'calacaschidas'\n",
    "bucket_files = boto3.client('s3').list_objects(Bucket=bucket)['Contents']\n",
    "bucket_files = [x['Key'] for x in bucket_files][1:]\n",
    "\n",
    "bucket_file = 'Doc3.pdf'\n",
    "file_path = os.path.join('images', bucket_file)\n",
    "if bucket_file not in os.listdir('images'):\n",
    "    boto3.client('s3').download_file(\n",
    "        bucket, \n",
    "        file_path, \n",
    "        file_path\n",
    "    )\n",
    "df_tables, df_text = get_aws_analyze_document(file_path)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tables)"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_digit_ocurrence_index(list_strings):\n",
    "    list_indexes = list_strings.index\n",
    "    for index, string in enumerate(list_strings):\n",
    "        if re.search('[0-9]{1}', string) is not None:\n",
    "            return list_indexes[index]\n",
    "    return -1\n",
    "\n",
    "def get_right_down_values(label_location):\n",
    "    # Get right value\n",
    "    aux = df_tables[label_location[0]].iloc[label_location[2]]\n",
    "    aux = aux[label_location[1]+1:]\n",
    "    right_index = get_first_digit_ocurrence_index(aux)\n",
    "    right_value = ''\n",
    "    if right_index != -1:\n",
    "        right_value = aux[right_index]\n",
    "    # Get down value\n",
    "    aux = df_tables[0][label_location[1]][label_location[2]+1:]\n",
    "    down_index = get_first_digit_ocurrence_index(aux)\n",
    "    down_value = ''\n",
    "    if down_index != -1:\n",
    "        down_value = aux[down_index]\n",
    "    return (right_value, down_value)"
>>>>>>> bfd0e2edee4bad119c75e9ec015be15e7986633e
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_text)"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_label_location = {\n",
    "    'Total activos': [0, 2, 9]\n",
    "}\n",
    "for label in output_label_location.keys():\n",
    "    right_value, down_value = get_right_down_values(output_label_location[label])\n",
    "    # Decisions"
>>>>>>> bfd0e2edee4bad119c75e9ec015be15e7986633e
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nbucket = 'text0detection'\\nbucket_files = boto3.client('s3').list_objects(Bucket=bucket)['Contents']\\nbucket_files = [x['Key'] for x in bucket_files][1:]\\nbucket_files = ['Doc1.pdf', 'Doc2.pdf', 'Doc3.pdf']\\n\\nfile_tables = []\\nfile_text = []\\ntimes = []\\nstart_time = time.time()\\nfor bucket_file in bucket_files:\\n    begin_time = time.time()\\n    print(bucket_file)\\n    file_path = os.path.join('images', bucket_file)\\n    if bucket_file not in os.listdir('images'):\\n        boto3.client('s3').download_file(\\n            bucket, \\n            file_path, \\n            file_path\\n        )\\n    df_tables, df_text = get_aws_analyze_document(file_path)\\n    file_tables.append(df_tables)\\n    file_text.append(df_text)\\n    times.append(time.time() - begin_time)\\n    print(file_path, ' - Time: ', times[-1])\\nprint('Total time: ', time.time() - start_time)\\nprint('Mean time: ', np.mean(times))\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "'''\n",
    "bucket = 'text0detection'\n",
    "bucket_files = boto3.client('s3').list_objects(Bucket=bucket)['Contents']\n",
    "bucket_files = [x['Key'] for x in bucket_files][1:]\n",
    "bucket_files = ['Doc1.pdf', 'Doc2.pdf', 'Doc3.pdf']\n",
    "\n",
    "file_tables = []\n",
    "file_text = []\n",
    "times = []\n",
    "start_time = time.time()\n",
    "for bucket_file in bucket_files:\n",
    "    begin_time = time.time()\n",
    "    print(bucket_file)\n",
    "    file_path = os.path.join('images', bucket_file)\n",
    "    if bucket_file not in os.listdir('images'):\n",
    "        boto3.client('s3').download_file(\n",
    "            bucket, \n",
    "            file_path, \n",
    "            file_path\n",
    "        )\n",
    "    df_tables, df_text = get_aws_analyze_document(file_path)\n",
    "    file_tables.append(df_tables)\n",
    "    file_text.append(df_text)\n",
    "    times.append(time.time() - begin_time)\n",
    "    print(file_path, ' - Time: ', times[-1])\n",
    "print('Total time: ', time.time() - start_time)\n",
    "print('Mean time: ', np.mean(times))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "ciencia_datos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
